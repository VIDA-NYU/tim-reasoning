{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf6a7adc20594324bbdb4df1d3ce59d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd3cda11ef6e460b8ee42cb4a42e84a9",
              "IPY_MODEL_d1d8fe040c6c49c38a9c41cff20c704f",
              "IPY_MODEL_ef7e9f67c384459e835785ee53087ea8"
            ],
            "layout": "IPY_MODEL_d54fc4a12e92417ba51a0fedfc03359f"
          }
        },
        "fd3cda11ef6e460b8ee42cb4a42e84a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96959d3075b418db5ac55585d9362d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f9bd1bb6e896461693ad530673e95c14",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d1d8fe040c6c49c38a9c41cff20c704f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c2b8a84fd164f75b186a7c43ac171d8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a07d01195e044d9a90608bf45fcf567d",
            "value": 2
          }
        },
        "ef7e9f67c384459e835785ee53087ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15022fb1f72f441e8298a8d768385e79",
            "placeholder": "​",
            "style": "IPY_MODEL_dab04cb0df0643c9ac1dec85591deeb0",
            "value": " 2/2 [00:01&lt;00:00,  1.34it/s]"
          }
        },
        "d54fc4a12e92417ba51a0fedfc03359f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d96959d3075b418db5ac55585d9362d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9bd1bb6e896461693ad530673e95c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c2b8a84fd164f75b186a7c43ac171d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07d01195e044d9a90608bf45fcf567d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15022fb1f72f441e8298a8d768385e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dab04cb0df0643c9ac1dec85591deeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install libs and import them"
      ],
      "metadata": {
        "id": "tkghviQrc4tL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "import subprocess\n",
        "from nltk import *\n",
        "from nltk.sem import Expression\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "ERUeGz3v7CXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e674bff-0a26-4a80-d77a-7681257919d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install prover9 from external source [Currently not working]"
      ],
      "metadata": {
        "id": "uprn_P-Jc9Xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://www.cs.unm.edu/~mccune/prover9/download/LADR-2009-11A.tar.gz\n",
        "# !tar -xzvf LADR-2009-11A.tar.gz\n",
        "# !cd LADR-2009-11A\n",
        "# !make all\n",
        "\n",
        "# prover = nltk.Prover9()\n",
        "# prover.config_prover9(binary_location='LADR-2009-11A')\n"
      ],
      "metadata": {
        "id": "iE-2LL4vXX5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A sample First order logic validation with expression and \"assumptions\""
      ],
      "metadata": {
        "id": "bEheG2oqdEPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "read_expr = Expression.fromstring\n",
        "p1 = read_expr('man(socrates)')\n",
        "p2 = read_expr('all x.(man(x) -> mortal(x))')\n",
        "c  = read_expr('mortal(socrates)')\n",
        "\n",
        "print(TableauProver().prove(c, [p1,p2], verbose=True))\n",
        "\n",
        "print(ResolutionProver().prove(c, [p1,p2], verbose=True))"
      ],
      "metadata": {
        "id": "lkIxBz4h6Bgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "552dec93-4694-45d7-9735-71b1642485b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man(socrates)\n",
            "   -mortal(socrates)\n",
            "      all x.(man(x) -> mortal(x)):   []\n",
            "            --> Using 'socrates'\n",
            "         (man(socrates) -> mortal(socrates))\n",
            "            -man(socrates)\n",
            "               CLOSED\n",
            "            mortal(socrates)\n",
            "               CLOSED\n",
            "True\n",
            "[1] {-mortal(socrates)}     A \n",
            "[2] {man(socrates)}         A \n",
            "[3] {-man(z2), mortal(z2)}  A \n",
            "[4] {-man(socrates)}        (1, 3) \n",
            "[5] {mortal(socrates)}      (2, 3) \n",
            "[6] {}                      (1, 5) \n",
            "\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, same expression without assumptions."
      ],
      "metadata": {
        "id": "TZveqLyfcpc-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "read_expr = Expression.fromstring\n",
        "c  = read_expr('mortal(socrates)')\n",
        "print(TableauProver().prove(c, verbose=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDk5GmQ1coHt",
        "outputId": "9634a12a-db62-4d92-e353-90770f1c5f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-mortal(socrates)\n",
            "   AGENDA EMPTY\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From logicllama paper,\n",
        "\n",
        "```∃x entire(x) <-> ¬serious(x)```\n",
        "\n",
        "but this doesn't validate."
      ],
      "metadata": {
        "id": "6wANsbeszeoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sem import Expression\n",
        "\n",
        "read_expr = Expression.fromstring\n",
        "\n",
        "# From logicllama paper\n",
        "# ∃x entire(x) <-> ¬serious(x)\n",
        "expr_1 = read_expr('exists x.(entire(x) <-> ¬serious(x))')\n",
        "\n",
        "# Prove the first implication\n",
        "proof_1 = TableauProver().prove(expr_1, verbose=True)\n",
        "print(proof_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeEuf1LQYDzY",
        "outputId": "a7dfba53-9876-45f8-b233-c37db6b61fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-exists x.(entire(x) <-> ¬serious(x))\n",
            "   all x.-(entire(x) <-> ¬serious(x)):   []\n",
            "         --> Using 'z3'\n",
            "      -(entire(z3) <-> ¬serious(z3))\n",
            "         entire(z3)\n",
            "            -¬serious(z3)\n",
            "               all x.-(entire(x) <-> ¬serious(x)):   [z3]\n",
            "                     --> Variables Exhausted\n",
            "                  AGENDA EMPTY\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.sem import Expression\n",
        "from nltk.inference.tableau import TableauProver\n",
        "from nltk.inference.resolution import ResolutionProver\n",
        "\n",
        "read_expr = Expression.fromstring\n",
        "\n",
        "# FOL statements\n",
        "# ∀x (entire(x) -> ¬serious(x)) ∧ ∀x (serious(x) -> ¬entire(x))\n",
        "expr_combined = read_expr('all x.(entire(x) -> ¬serious(x)) & all x.(serious(x) -> ¬entire(x))')\n",
        "\n",
        "# Assumptions\n",
        "assumptions = [\n",
        "    read_expr('entire(x) -> ¬serious(x)'),  # Assumption: John is entire\n",
        "    read_expr('serious(x) -> ¬entire(x)'),  # Assumption: John is serious\n",
        "    # Add more assumptions if known or relevant\n",
        "]\n",
        "\n",
        "# Adding assumptions to the proof\n",
        "# Using Tableau Prover\n",
        "proof_tableau = TableauProver().prove(expr_combined, assumptions)\n",
        "print(proof_tableau)  # This will print True if the proof is successful\n",
        "\n",
        "# Using Resolution Prover\n",
        "proof_resolution = ResolutionProver().prove(expr_combined, assumptions, verbose=True)\n",
        "print(proof_resolution)  # This will show the resolution steps if the proof is successful\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc8NZv49oOzW",
        "outputId": "5a7e99f2-a6ce-4570-b47b-068d2e35702a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "[ 1] {entire(z8), serious(z7)}         A \n",
            "[ 2] {entire(z10), -¬entire(z9)}       A \n",
            "[ 3] {-¬serious(z12), serious(z11)}    A \n",
            "[ 4] {-¬serious(z14), -¬entire(z13)}   A \n",
            "[ 5] {-entire(z15), ¬serious(z15)}     A \n",
            "[ 6] {-serious(z16), ¬entire(z16)}     A \n",
            "[ 7] {¬serious(z15), serious(z7)}      (1, 5) \n",
            "[ 8] {¬entire(z16), entire(z8)}        (1, 6) \n",
            "[ 9] {¬serious(z15), -¬entire(z9)}     (2, 5) \n",
            "[10] {-serious(z16), entire(z10)}      (2, 6) \n",
            "[11] {entire(z10), entire(z8)}         (1, 10) \n",
            "[12] {entire(z8), entire(z10)}         (2, 8) \n",
            "[13] {-entire(z15), serious(z11)}      (3, 5) \n",
            "[14] {serious(z11), serious(z7)}       (1, 13) \n",
            "[15] {serious(z11), -¬entire(z9)}      (2, 13) \n",
            "[16] {¬entire(z16), -¬serious(z12)}    (3, 6) \n",
            "[17] {-¬serious(z12), entire(z10)}     (2, 16) \n",
            "[18] {serious(z7), serious(z11)}       (3, 7) \n",
            "[19] {-¬entire(z9), serious(z11)}      (3, 9) \n",
            "[20] {entire(z10), -¬serious(z12)}     (3, 10) \n",
            "[21] {-entire(z15), -¬entire(z13)}     (4, 5) \n",
            "[22] {-¬entire(z13), serious(z7)}      (1, 21) \n",
            "[23] {-¬entire(z13), -¬entire(z9)}     (2, 21) \n",
            "[24] {-serious(z16), -¬serious(z14)}   (4, 6) \n",
            "[25] {-¬serious(z14), entire(z8)}      (1, 24) \n",
            "[26] {-¬serious(z14), -¬serious(z12)}  (3, 24) \n",
            "[27] {serious(z7), -¬entire(z13)}      (4, 7) \n",
            "[28] {entire(z8), -¬serious(z14)}      (4, 8) \n",
            "[29] {-¬entire(z9), -¬entire(z13)}     (4, 9) \n",
            "[30] {-¬serious(z12), -¬serious(z14)}  (4, 16) \n",
            "[31] {¬entire(z16), ¬serious(z8)}      (5, 8) \n",
            "[32] {¬serious(z8), entire(z10)}       (2, 31) \n",
            "[33] {¬entire(z16), serious(z11)}      (3, 31) \n",
            "[34] {serious(z11), entire(z10)}       (2, 33) \n",
            "[35] {entire(z10), serious(z11)}       (3, 32) \n",
            "[36] {}                                (4, 31) \n",
            "\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LogicLlama inference"
      ],
      "metadata": {
        "id": "wbpyuiKlawii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install peft\n",
        "!pip install datasets transformers[sentencepiece]\n",
        "!pip install sentencepiece\n",
        "\n",
        "import torch\n",
        "from functools import partial\n",
        "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
        "from peft import PeftModel, prepare_model_for_int8_training\n",
        "# from utils import TranslationDataPreparer, ContinuousCorrectionDataPreparer, make_parent_dirs\n",
        "# from fol_parser import parse_text_FOL_to_tree\n",
        "# from generate import llama_generate\n",
        "\n",
        "base_model='huggyllama/llama-7b' # TODO: fill in with the path to the llama-7b model\n",
        "prompt_template_path='data/prompt_templates'\n",
        "load_in_8bit = True\n",
        "max_output_len = 128\n",
        "\n",
        "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
        "tokenizer.add_special_tokens({\n",
        "    \"eos_token\": \"</s>\",\n",
        "    \"bos_token\": \"<s>\",\n",
        "    \"unk_token\": '<unk>',\n",
        "    \"pad_token\": '<unk>',\n",
        "})\n",
        "tokenizer.padding_side = \"left\"  # Allow batched inference\n",
        "\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.1,\n",
        "    top_p=0.75,\n",
        "    top_k=40,\n",
        "    num_beams=1\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "PaLmLBBVav57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llama_model = LlamaForCausalLM.from_pretrained(\n",
        "    base_model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map='auto',\n",
        ")\n",
        "llama_model = prepare_model_for_int8_training(llama_model)\n",
        "\n",
        "peft_path='yuan-yang/LogicLLaMA-7b-direct-translate-delta-v0'\n",
        "model = PeftModel.from_pretrained(\n",
        "    llama_model,\n",
        "    peft_path,\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "# model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "bf6a7adc20594324bbdb4df1d3ce59d8",
            "fd3cda11ef6e460b8ee42cb4a42e84a9",
            "d1d8fe040c6c49c38a9c41cff20c704f",
            "ef7e9f67c384459e835785ee53087ea8",
            "d54fc4a12e92417ba51a0fedfc03359f",
            "d96959d3075b418db5ac55585d9362d0",
            "f9bd1bb6e896461693ad530673e95c14",
            "9c2b8a84fd164f75b186a7c43ac171d8",
            "a07d01195e044d9a90608bf45fcf567d",
            "15022fb1f72f441e8298a8d768385e79",
            "dab04cb0df0643c9ac1dec85591deeb0"
          ]
        },
        "id": "AEv9oMA80sng",
        "outputId": "37f93b2f-c182-458d-ada0-5dcbebce16b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf6a7adc20594324bbdb4df1d3ce59d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}