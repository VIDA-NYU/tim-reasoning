{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c488b465",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/py38/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/rl3725/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135f7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import snapshot_download\n",
    "#snapshot_download(repo_id=\"meta-llama/Llama-2-7b-chat-hf\", local_dir=\"./data/7b-chat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c5fde",
   "metadata": {},
   "source": [
    "## 1. Zero-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3faa2002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:23<00:00, 71.88s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/vast/work/public/ml-datasets/llama-2/Llama-2-7b-hf\", use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/vast/work/public/ml-datasets/llama-2/Llama-2-7b-hf\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea369e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "Your are a reasoning system that has to identify in which step of a recipe the user is on given some inputs from a perception system.<</SYS>>\n",
      "\n",
      "Can you help me? [/INST]\n",
      "\n",
      "Of course! I'd be happy to help you identify the step of a recipe that a user is on based on inputs from a perception system. Can you please provide me with more details on the following:\n",
      "\n",
      "1. The recipe: Can you provide me with the name of the recipe or a brief description of it?\n",
      "2. The perception system: How does the perception system provide inputs to the reasoning system? For example, are the inputs in the form of text, images, or audio?\n",
      "3. The user's inputs: What are the user's inputs in the recipe? For example, are they selecting ingredients, following a list of instructions, or providing feedback on the cooking process?\n",
      "\n",
      "Once I have this information, I can develop a reasoning system that can accurately identify the step of the recipe that the user is on based on the inputs from the perception system.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a reasoning system that has to identify in which step of a recipe the user is on given some inputs from a perception system.<</SYS>>\n",
    "\n",
    "Can you help me? [/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c5e0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "</s><s> [INST] <<SYS>>\n",
      "It's an oatmeal recipe and these are the steps:\n",
      "1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.,\n",
      "2: Add 1/2 cup water to the bowl.,\n",
      "3: Microwave for 30 seconds.,\n",
      "4: Add handful of raisins and stir.,\n",
      "5: Microwave for 60 more seconds then stir.,\n",
      "6: Top with banana slices.,\n",
      "7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
      "\n",
      "And these are the possible states detected by the perception system and their probabilities:\n",
      "oatmeal with water:0.54,\n",
      "oatmeal with raisins with banana with cinnamon:0.06,\n",
      "oatmeal with raisins:0.13,\n",
      "oatmeal with raisins with banana:0.01,\n",
      "oatmeal[dry]:0.15,\n",
      "oatmeal with raisins with banana with cinnamon with honey:0.06,\n",
      "cooked oatmeal:0.00,\n",
      "empty:0.01 <</SYS>>\n",
      "So, in which step of the recipe the user is?\n",
      "[/INST]\n",
      "Based on the information provided, the user is most likely in step 3 of the recipe, as the probabilities of the possible states detected by the perception system indicate that the user is most likely to be in the middle of microwaving the oatmeal for 30 seconds. The probabilities of the other steps are lower:\n",
      "\n",
      "* Oatmeal with water: 0.54 (the user has already measured the oats and added water, but has not yet microwaved it)\n",
      "* Oatmeal with raisins with banana with cinnamon: 0.06 (the user has added raisins and banana to the oatmeal, but has not yet microwaved it)\n",
      "* Oatmeal with raisins: 0.13 (the user has added raisins to the oatmeal, but has not yet microwaved it)\n",
      "* Oatmeal with raisins with banana: 0.01 (the user has added raisins and banana to the oatmeal, but has not yet microwaved it)\n",
      "* Oatmeal (dry): 0.15 (the user has measured the oats but has not yet added water or microwaved it)\n",
      "* Cooked oatmeal: 0.00 (the user has not yet cooked the oatmeal)\n",
      "* Empty: 0.01 (the user has not yet added any ingredients to the oatmeal)\n",
      "\n",
      "Therefore, the user is most likely in step 3 of the recipe, microwaving the oatmeal for 30 seconds.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "It's an oatmeal recipe and these are the steps:\n",
    "1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.,\n",
    "2: Add 1/2 cup water to the bowl.,\n",
    "3: Microwave for 30 seconds.,\n",
    "4: Add handful of raisins and stir.,\n",
    "5: Microwave for 60 more seconds then stir.,\n",
    "6: Top with banana slices.,\n",
    "7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
    "\n",
    "And these are the possible states detected by the perception system and their probabilities:\n",
    "oatmeal with water:0.54,\n",
    "oatmeal with raisins with banana with cinnamon:0.06,\n",
    "oatmeal with raisins:0.13,\n",
    "oatmeal with raisins with banana:0.01,\n",
    "oatmeal[dry]:0.15,\n",
    "oatmeal with raisins with banana with cinnamon with honey:0.06,\n",
    "cooked oatmeal:0.00,\n",
    "empty:0.01 <</SYS>>\n",
    "So, in which step of the recipe the user is?\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be61427",
   "metadata": {},
   "source": [
    "#### Adding Information about the States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "070dd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./data/7b-chat\", use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./data/7b-chat\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e348f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "Your are a reasoning system that has to identify in which step of a recipe the user is on given some inputs from a perception system.<</SYS>>\n",
      "\n",
      "Can you help me? [/INST]\n",
      "\n",
      "Of course! I'd be happy to help you identify the step of a recipe that a user is on based on inputs from a perception system. Can you please provide me with more details about the recipe and the inputs from the perception system? For example:\n",
      "\n",
      "* What is the name of the recipe?\n",
      "* What are the steps involved in the recipe?\n",
      "* What are the inputs from the perception system (e.g. images, text, audio)?\n",
      "* How does the perception system provide the inputs (e.g. through a web interface, a mobile app, a voice assistant)?\n",
      "\n",
      "Once I have this information, I can help you develop a reasoning system that can accurately identify the step of the recipe that the user is on based on the inputs from the perception system.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Your are a reasoning system that has to identify in which step of a recipe the user is on given some inputs from a perception system.<</SYS>>\n",
    "\n",
    "Can you help me? [/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1b961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "It's an oatmeal recipe and these are the steps:\n",
      "1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.,\n",
      "2: Add 1/2 cup water to the bowl.,\n",
      "3: Microwave for 30 seconds.,\n",
      "4: Add handful of raisins and stir.,\n",
      "5: Microwave for 60 more seconds then stir.,\n",
      "6: Top with banana slices.,\n",
      "7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
      "\n",
      "Step 1 is completed when the dry oatmeal is on the bowl.\n",
      "Step 2 is completed when there is water on the bowl.\n",
      "Step 3 is completed when the bowl is on the microwave.\n",
      "Step 4 is completed when there are raisins on the bowl.\n",
      "\n",
      "And these are the possible states detected by the perception system and their probabilities:\n",
      "oatmeal with water:0.54,\n",
      "oatmeal with raisins with banana with cinnamon:0.06,\n",
      "oatmeal with raisins:0.13,\n",
      "oatmeal with raisins with banana:0.01,\n",
      "oatmeal[dry]:0.15,\n",
      "oatmeal with raisins with banana with cinnamon with honey:0.06,\n",
      "cooked oatmeal:0.00,\n",
      "empty:0.01 <</SYS>>\n",
      "So, in which step of the recipe the user is?\n",
      "[/INST]\n",
      "Based on the information provided, the user is most likely in step 3, as the bowl is on the microwave with water in it. The probability of the user being in this step is 0.54, which is the highest probability among all the possible states.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "It's an oatmeal recipe and these are the steps:\n",
    "1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.,\n",
    "2: Add 1/2 cup water to the bowl.,\n",
    "3: Microwave for 30 seconds.,\n",
    "4: Add handful of raisins and stir.,\n",
    "5: Microwave for 60 more seconds then stir.,\n",
    "6: Top with banana slices.,\n",
    "7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
    "\n",
    "Step 1 is completed when the dry oatmeal is on the bowl.\n",
    "Step 2 is completed when there is water on the bowl.\n",
    "Step 3 is completed when the bowl is on the microwave.\n",
    "Step 4 is completed when there are raisins on the bowl.\n",
    "\n",
    "And these are the possible states detected by the perception system and their probabilities:\n",
    "oatmeal with water:0.54,\n",
    "oatmeal with raisins with banana with cinnamon:0.06,\n",
    "oatmeal with raisins:0.13,\n",
    "oatmeal with raisins with banana:0.01,\n",
    "oatmeal[dry]:0.15,\n",
    "oatmeal with raisins with banana with cinnamon with honey:0.06,\n",
    "cooked oatmeal:0.00,\n",
    "empty:0.01 <</SYS>>\n",
    "So, in which step of the recipe the user is?\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8eba7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "Your are wrong, the user is on step 2 <</SYS>>\n",
      "[/INST]\n",
      "My apologies, you are correct. The user is currently on step 2. Thank you for correcting me!</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Your are wrong, the user is on step 2 <</SYS>>\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cad558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "Ok. <</SYS>>\n",
      "So, what is the next step in the recipe?\n",
      "[/INST]\n",
      " Great, let's continue with the recipe! The next step is to cook the pasta in boiling water.\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Add the pasta to a large pot of boiling, salted water.\n",
      "2. Cook the pasta for 8-10 minutes, or until it's al dente.\n",
      "3. Drain the pasta in a colander and rinse it with cold water to stop the cooking process.\n",
      "\n",
      "Once the pasta is cooked, you can proceed to the next step in the recipe, which is to prepare the sauce. Do you have any questions or would you like me to provide more instructions?</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "Ok. <</SYS>>\n",
    "So, what is the next step in the recipe?\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6163c3b8",
   "metadata": {},
   "source": [
    "## 2. Few-Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc7f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(file_paths):\n",
    "    data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            recipe_data = json.load(file)\n",
    "            data.extend(recipe_data)\n",
    "    return data\n",
    "\n",
    "def seconds_to_minutes(seconds):\n",
    "    minutes = seconds // 60\n",
    "    remaining_seconds = seconds % 60\n",
    "\n",
    "    return minutes, remaining_seconds\n",
    "\n",
    "def two_digit_number(number):\n",
    "    return f'{number:02}'\n",
    "\n",
    "def make_hr_state(state):\n",
    "    new_state = state.replace('+', ' with ')\n",
    "    new_state = new_state.replace('[', '(')\n",
    "    new_state = new_state.replace(']', ')')\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "def extract_data(data, include_step=True):\n",
    "    dataset = []\n",
    "    times = set()\n",
    "    for entry in data:\n",
    "        raw_seconds = int(entry['timestamp'])\n",
    "        if raw_seconds in times:\n",
    "            continue\n",
    "        else:\n",
    "            times.add(raw_seconds)\n",
    "        minutes, seconds = seconds_to_minutes(raw_seconds)\n",
    "        image_data_list = entry['objects']\n",
    "        step = entry['step']\n",
    "        \n",
    "        for image_data in image_data_list:\n",
    "            object = image_data['label']\n",
    "            if 'state' in image_data:\n",
    "                states = [f'{make_hr_state(s)}: {round(v,2)}' for s,v in image_data['state'].items()]\n",
    "                text = f'At 01:{two_digit_number(minutes)}:{two_digit_number(seconds)} PM, the possible object states for {object} are: {\", \".join(states)}. The predicted step is:'\n",
    "                if include_step:\n",
    "                    text = text + f' {step}'\n",
    "                dataset.append(text)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e8dbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:27<00:00, 29.08s/it]\n",
      "/ext3/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/ext3/miniconda3/envs/py38/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/vast/work/public/ml-datasets/llama-2/Llama-2-13b-chat-hf\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/vast/work/public/ml-datasets/llama-2/Llama-2-13b-chat-hf\", device_map=\"auto\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"./data/13b-quantized\")\n",
    "#model = AutoModelForCausalLM.from_pretrained(\"./data/13b-quantized\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04852bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At 01:00:14 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.47, dripper with filter: 0.3, tea-bag: 0.05, tea-bag with water: 0.15, dripper with filter with coffee(wet): 0.05, dripper(empty): 0.05, empty: 0.09. The predicted step is: 1',\n",
       " 'At 01:00:15 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.61, dripper with filter: 0.01, tea-bag: 0.02, tea-bag with water: 0.06, dripper with filter with coffee(wet): 0.04, dripper(empty): 0.11, empty: 0.09, water: 0.06. The predicted step is: 1',\n",
       " 'At 01:00:15 PM, the possible object states for bowl are: oatmeal(cooked): 0.55, oatmeal(dry): 0.45. The predicted step is: 1',\n",
       " 'At 01:00:16 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.52, dripper with filter: 0.07, tea-bag: 0.12, tea-bag with water: 0.03, dripper with filter with coffee(wet): 0.07, dripper(empty): 0.06, empty: 0.05, water: 0.04, dripper with filter with coffee(drained): 0.18. The predicted step is: 1',\n",
       " 'At 01:00:16 PM, the possible object states for bowl are: oatmeal(cooked): 0.58, oatmeal(dry): 0.26, oatmeal with water: 0.11, oatmeal with raisins with banana: 0.08. The predicted step is: 1',\n",
       " 'At 01:00:17 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.7, dripper with filter: 0.09, tea-bag: 0.01, tea-bag with water: 0.13, dripper with filter with coffee(wet): 0.03, dripper(empty): 0.0, empty: 0.0, water: 0.03, dripper with filter with coffee(drained): 0.0. The predicted step is: 1',\n",
       " 'At 01:00:17 PM, the possible object states for bowl are: oatmeal(cooked): 0.22, oatmeal(dry): 0.37, oatmeal with water: 0.09, oatmeal with raisins with banana: 0.05, oatmeal with raisins: 0.28, oatmeal with raisins with banana with cinnamon with honey: 0.05, empty: 0.07. The predicted step is: 1',\n",
       " 'At 01:00:18 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.37, dripper with filter: 0.16, tea-bag: 0.05, tea-bag with water: 0.08, dripper with filter with coffee(wet): 0.17, dripper(empty): 0.09, empty: 0.08, water: 0.01, dripper with filter with coffee(drained): 0.0. The predicted step is: 1',\n",
       " 'At 01:00:18 PM, the possible object states for bowl are: oatmeal(cooked): 0.18, oatmeal(dry): 0.11, oatmeal with water: 0.71, oatmeal with raisins with banana: 0.0, oatmeal with raisins: 0.0, oatmeal with raisins with banana with cinnamon with honey: 0.0, empty: 0.0. The predicted step is: 1',\n",
       " 'At 01:00:19 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.4, dripper with filter: 0.17, tea-bag: 0.13, tea-bag with water: 0.1, dripper with filter with coffee(wet): 0.09, dripper(empty): 0.01, empty: 0.01, water: 0.04, dripper with filter with coffee(drained): 0.05. The predicted step is: 1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = ['./perception_outputs/data_oatmeal_2023.11.03-18.51.03.json']\n",
    "data = read_json(file_paths)\n",
    "train_dataset = extract_data(data)\n",
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b92bc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "You are a reasoning system that has to identify which step of a recipe the user is on, given some object states identified by a perception system.<</SYS>>\n",
      "\n",
      "Can you help me? I will give you an example. [/INST]\n",
      "  Of course! I'd be happy to help. Please provide the recipe steps and the object states identified by the perception system, and I'll do my best to determine which step the user is on.\n",
      "\n",
      "Here's an example to get started:\n",
      "\n",
      "Recipe Steps:\n",
      "\n",
      "1. Preheat the oven to 350°F (180°C).\n",
      "2. Mix together flour, sugar, and butter to form a dough.\n",
      "3. Roll out the dough into a circle.\n",
      "4. Place the dough into a greased pie dish.\n",
      "5. Fill the dough with a mixture of eggs, milk, and vanilla extract.\n",
      "6. Bake for 25-30 minutes, or until the crust is golden brown and the filling is set.\n",
      "\n",
      "Object States:\n",
      "\n",
      "* The oven is on and preheating to 350°F (180°C).\n",
      "* A mixing bowl contains flour, sugar, and butter.\n",
      "* A rolling pin is on the counter.\n",
      "* A greased pie dish is on the counter.\n",
      "* A measuring cup containing eggs, milk, and vanilla extract is on the counter.\n",
      "\n",
      "Can you tell me which step the user is on based on these object states?</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "You are a reasoning system that has to identify which step of a recipe the user is on, given some object states identified by a perception system.<</SYS>>\n",
    "\n",
    "Can you help me? I will give you an example. [/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2678262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "It's an oatmeal recipe and these are the steps:\n",
      "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
      "Step 2: Add 1/2 cup water to the bowl.\n",
      "Step 3: Microwave for 30 seconds.\n",
      "Step 4: Add handful of raisins and stir.\n",
      "Step 5: Microwave for 60 more seconds then stir.\n",
      "Step 6: Top with banana slices.\n",
      "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
      "\n",
      "Below you will see examples of object states identified by the perception system and the predicted steps for them.\n",
      "At 01:00:14 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.47, dripper with filter: 0.3, tea-bag: 0.05, tea-bag with water: 0.15, dripper with filter with coffee(wet): 0.05, dripper(empty): 0.05, empty: 0.09. The predicted step is: 1. At 01:00:15 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.61, dripper with filter: 0.01, tea-bag: 0.02, tea-bag with water: 0.06, dripper with filter with coffee(wet): 0.04, dripper(empty): 0.11, empty: 0.09, water: 0.06. The predicted step is: 1. At 01:00:15 PM, the possible object states for bowl are: oatmeal(cooked): 0.55, oatmeal(dry): 0.45. The predicted step is: 1. At 01:00:16 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.52, dripper with filter: 0.07, tea-bag: 0.12, tea-bag with water: 0.03, dripper with filter with coffee(wet): 0.07, dripper(empty): 0.06, empty: 0.05, water: 0.04, dripper with filter with coffee(drained): 0.18. The predicted step is: 1. At 01:00:16 PM, the possible object states for bowl are: oatmeal(cooked): 0.58, oatmeal(dry): 0.26, oatmeal with water: 0.11, oatmeal with raisins with banana: 0.08. The predicted step is: 1. At 01:00:17 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.7, dripper with filter: 0.09, tea-bag: 0.01, tea-bag with water: 0.13, dripper with filter with coffee(wet): 0.03, dripper(empty): 0.0, empty: 0.0, water: 0.03, dripper with filter with coffee(drained): 0.0. The predicted step is: 1. At 01:00:17 PM, the possible object states for bowl are: oatmeal(cooked): 0.22, oatmeal(dry): 0.37, oatmeal with water: 0.09, oatmeal with raisins with banana: 0.05, oatmeal with raisins: 0.28, oatmeal with raisins with banana with cinnamon with honey: 0.05, empty: 0.07. The predicted step is: 1. At 01:00:18 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.37, dripper with filter: 0.16, tea-bag: 0.05, tea-bag with water: 0.08, dripper with filter with coffee(wet): 0.17, dripper(empty): 0.09, empty: 0.08, water: 0.01, dripper with filter with coffee(drained): 0.0. The predicted step is: 1. At 01:00:18 PM, the possible object states for bowl are: oatmeal(cooked): 0.18, oatmeal(dry): 0.11, oatmeal with water: 0.71, oatmeal with raisins with banana: 0.0, oatmeal with raisins: 0.0, oatmeal with raisins with banana with cinnamon with honey: 0.0, empty: 0.0. The predicted step is: 1. At 01:00:19 PM, the possible object states for mug are: dripper with filter with coffee(dry): 0.4, dripper with filter: 0.17, tea-bag: 0.13, tea-bag with water: 0.1, dripper with filter with coffee(wet): 0.09, dripper(empty): 0.01, empty: 0.01, water: 0.04, dripper with filter with coffee(drained): 0.05. The predicted step is: 1<</SYS>>\n",
      "Are you ready to predict which step of a recipe the user is on, given some object states identified by a perception system?\n",
      "[/INST]\n",
      "Yes, I'm ready to predict the step of the recipe based on the object states identified by the perception system. Please provide the object states for each step, and I'll use a machine learning model to predict the corresponding step.\n",
      "\n",
      "Here's the list of object states for each step of the oatmeal recipe:\n",
      "\n",
      "Step 1:\n",
      "\n",
      "* Mug: dripper with filter with coffee(dry), water: 0\n",
      "* Bowl: oatmeal(dry): 0.55, oatmeal(cooked): 0.0\n",
      "\n",
      "Step 2:\n",
      "\n",
      "* Mug: dripper with filter with coffee(dry), water: 0.15\n",
      "* Bowl: oatmeal(dry): 0.45, oatmeal(cooked): 0.0\n",
      "\n",
      "Step 3:\n",
      "\n",
      "* Mug: dripper with filter with coffee(wet), water: 0.08\n",
      "* Bowl: oatmeal(dry): 0.26, oatmeal(cooked): 0.0\n",
      "\n",
      "Step 4:\n",
      "\n",
      "* Mug: dripper with filter with coffee(drained), water: 0.03\n",
      "* Bowl: oatmeal(cooked): 0.58, oatmeal(dry): 0.26\n",
      "\n",
      "Step 5:\n",
      "\n",
      "* Mug: dripper with filter with coffee(dry), water: 0.13\n",
      "* Bowl: oatmeal(cooked): 0.55, oatmeal(dry): 0.37\n",
      "\n",
      "Step 6:\n",
      "\n",
      "* Mug: dripper with filter with coffee(wet), water: 0.01\n",
      "* Bowl: oatmeal(cooked): 0.58, oatmeal(dry): 0.26\n",
      "\n",
      "Step 7:\n",
      "\n",
      "* Mug: dripper with filter with coffee(drained), water: 0.0\n",
      "* Bowl: oatmeal(cooked): 0.55, oatmeal(dry): 0.37\n",
      "\n",
      "Please provide the object states for each step, and I'll use a machine learning model to predict the corresponding step.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "It's an oatmeal recipe and these are the steps:\n",
    "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
    "Step 2: Add 1/2 cup water to the bowl.\n",
    "Step 3: Microwave for 30 seconds.\n",
    "Step 4: Add handful of raisins and stir.\n",
    "Step 5: Microwave for 60 more seconds then stir.\n",
    "Step 6: Top with banana slices.\n",
    "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
    "\n",
    "Below you will see examples of object states identified by the perception system and the predicted steps for them.\n",
    "{'. '.join(train_dataset[:10])}<</SYS>>\n",
    "Are you ready to predict which step of a recipe the user is on, given some object states identified by a perception system?\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b9355a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['At 01:00:02 PM, the possible object states for bowl are: oatmeal with raisins: 0.21, oatmeal with water: 0.2, oatmeal(dry): 0.11, empty: 0.2, oatmeal with raisins with banana: 0.09, oatmeal(cooked): 0.73, oatmeal with raisins with banana with cinnamon: 0.09. The predicted step is:',\n",
       " 'At 01:00:03 PM, the possible object states for bowl are: oatmeal with raisins: 0.29, oatmeal with water: 0.27, oatmeal(dry): 0.06, empty: 0.11, oatmeal with raisins with banana: 0.12, oatmeal(cooked): 0.37, oatmeal with raisins with banana with cinnamon: 0.04, oatmeal with raisins with banana with cinnamon with honey: 0.05. The predicted step is:',\n",
       " 'At 01:00:03 PM, the possible object states for bowl are: empty: 0.73, oatmeal with raisins with banana with cinnamon with honey: 0.18, oatmeal with raisins with banana with cinnamon: 0.09. The predicted step is:',\n",
       " 'At 01:00:04 PM, the possible object states for bowl are: oatmeal with raisins: 0.2, oatmeal with water: 0.19, oatmeal(dry): 0.03, empty: 0.55, oatmeal with raisins with banana: 0.02, oatmeal(cooked): 0.0, oatmeal with raisins with banana with cinnamon: 0.0, oatmeal with raisins with banana with cinnamon with honey: 0.0. The predicted step is:',\n",
       " 'At 01:00:04 PM, the possible object states for bowl are: empty: 0.24, oatmeal with raisins with banana with cinnamon with honey: 0.11, oatmeal with raisins with banana with cinnamon: 0.04, oatmeal(cooked): 0.33, oatmeal with water: 0.16, oatmeal with raisins with banana: 0.13, oatmeal(dry): 0.07. The predicted step is:',\n",
       " 'At 01:00:04 PM, the possible object states for mug are: dripper with filter: 0.91, dripper with filter with coffee(dry): 0.09. The predicted step is:',\n",
       " 'At 01:00:05 PM, the possible object states for bowl are: oatmeal with raisins: 0.23, oatmeal with water: 0.25, oatmeal(dry): 0.02, empty: 0.14, oatmeal with raisins with banana: 0.09, oatmeal(cooked): 0.16, oatmeal with raisins with banana with cinnamon: 0.05, oatmeal with raisins with banana with cinnamon with honey: 0.05. The predicted step is:',\n",
       " 'At 01:00:05 PM, the possible object states for bowl are: empty: 0.36, oatmeal with raisins with banana with cinnamon with honey: 0.11, oatmeal with raisins with banana with cinnamon: 0.02, oatmeal(cooked): 0.11, oatmeal with water: 0.1, oatmeal with raisins with banana: 0.15, oatmeal(dry): 0.02, oatmeal with raisins: 0.14. The predicted step is:',\n",
       " 'At 01:00:05 PM, the possible object states for mug are: dripper with filter: 0.58, dripper with filter with coffee(dry): 0.38, dripper(empty): 0.01, dripper with filter with coffee(wet): 0.03, tea-bag with water: 0.02. The predicted step is:',\n",
       " 'At 01:00:06 PM, the possible object states for bowl are: oatmeal with raisins: 0.23, oatmeal with water: 0.15, oatmeal(dry): 0.0, empty: 0.02, oatmeal with raisins with banana: 0.06, oatmeal(cooked): 0.44, oatmeal with raisins with banana with cinnamon: 0.07, oatmeal with raisins with banana with cinnamon with honey: 0.03. The predicted step is:']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths = ['./perception_outputs/data_oatmeal_2023.11.03-19.04.04.json']\n",
    "data = read_json(file_paths)\n",
    "test_dataset = extract_data(data, include_step=False)\n",
    "test_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce3e2f96-c331-41ef-8505-ca0312ea614a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "It's an oatmeal recipe and these are the steps:\n",
      "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
      "Step 2: Add 1/2 cup water to the bowl.\n",
      "Step 3: Microwave for 30 seconds.\n",
      "Step 4: Add handful of raisins and stir.\n",
      "Step 5: Microwave for 60 more seconds then stir.\n",
      "Step 6: Top with banana slices.\n",
      "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
      "\n",
      "Below you will see examples of object states identified by the perception system. Please predict the steps for them.\n",
      "At 01:00:03 PM, the possible object states for bowl are: oatmeal with raisins: 0.29, oatmeal with water: 0.27, oatmeal(dry): 0.06, empty: 0.11, oatmeal with raisins with banana: 0.12, oatmeal(cooked): 0.37, oatmeal with raisins with banana with cinnamon: 0.04, oatmeal with raisins with banana with cinnamon with honey: 0.05. The predicted step is:<</SYS>>\n",
      "\n",
      "[/INST]\n",
      "Based on the possible object states you provided, the predicted step is:\n",
      "\n",
      "Step 4: Add handful of raisins and stir.\n",
      "\n",
      "The perception system has identified that the current state of the bowl is oatmeal with raisins (0.29), so the next step would be to add a handful of raisins and stir.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "It's an oatmeal recipe and these are the steps:\n",
    "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
    "Step 2: Add 1/2 cup water to the bowl.\n",
    "Step 3: Microwave for 30 seconds.\n",
    "Step 4: Add handful of raisins and stir.\n",
    "Step 5: Microwave for 60 more seconds then stir.\n",
    "Step 6: Top with banana slices.\n",
    "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
    "\n",
    "Below you will see examples of object states identified by the perception system. Please predict the steps for them.\n",
    "{test_dataset[1]}<</SYS>>\n",
    "\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9bb55d4-ab42-415b-a734-cfa9c746cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "It's an oatmeal recipe and these are the steps:\n",
      "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
      "Step 2: Add 1/2 cup water to the bowl.\n",
      "Step 3: Microwave for 30 seconds.\n",
      "Step 4: Add handful of raisins and stir.\n",
      "Step 5: Microwave for 60 more seconds then stir.\n",
      "Step 6: Top with banana slices.\n",
      "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
      "\n",
      "Below you will see examples of object states identified by the perception system. Please predict the steps for them.\n",
      "At 01:00:06 PM, the possible object states for bowl are: empty: 0.72, oatmeal with raisins with banana with cinnamon with honey: 0.0, oatmeal with raisins with banana with cinnamon: 0.02, oatmeal(cooked): 0.19, oatmeal with water: 0.06, oatmeal with raisins with banana: 0.0, oatmeal(dry): 0.0, oatmeal with raisins: 0.0. The predicted step is:<</SYS>>\n",
      "\n",
      "[/INST]\n",
      "Based on the possible object states you provided, the predicted step is:\n",
      "\n",
      "Step 3: Microwave for 30 seconds.\n",
      "\n",
      "The perception system has identified the bowl as containing oatmeal with raisins and water, but not yet cooked. Therefore, the next step would be to microwave the oatmeal for 30 seconds to cook it further.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "It's an oatmeal recipe and these are the steps:\n",
    "Step 1: Measure 4 Tablespoons of quick-cook oats and place in a microwave-safe bowl.\n",
    "Step 2: Add 1/2 cup water to the bowl.\n",
    "Step 3: Microwave for 30 seconds.\n",
    "Step 4: Add handful of raisins and stir.\n",
    "Step 5: Microwave for 60 more seconds then stir.\n",
    "Step 6: Top with banana slices.\n",
    "Step 7: Sprinkle with cinnamon and drizzle with honey before serving.\n",
    "\n",
    "Below you will see examples of object states identified by the perception system. Please predict the steps for them.\n",
    "{test_dataset[10]}<</SYS>>\n",
    "\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949a0a2b-fa96-4b48-a45d-c192deb63064",
   "metadata": {},
   "source": [
    "#### Free-form Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46c82962-c0e3-40ff-9dab-e8f2d7f41dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      "<s> \n",
      "<s> [INST] <<SYS>>\n",
      "When did the user start the step 1 of the recipe?<</SYS>>\n",
      "[/INST]\n",
      " As a system, I don't have the ability to track the user's actions or start times. The user may have started the step 1 of the recipe at any point in the past, and there is no information available to determine when exactly they started.\n",
      "\n",
      "However, if the user has provided any information or context about their progress in the recipe, it may be possible to infer when they started step 1 based on that information. For example, if the user has mentioned that they started the recipe yesterday, it may be reasonable to assume that they started step 1 on the previous day.\n",
      "\n",
      "Without any additional information, it is not possible to determine when the user started step 1 of the recipe with certainty.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "When did the user start the step 1 of the recipe?<</SYS>>\n",
    "[/INST]\n",
    "\"\"\"\n",
    "prompt_template=f'{prompt}'\n",
    "\n",
    "print(\"Output:\")\n",
    "\n",
    "input_ids = tokenizer(prompt_template, return_tensors='pt').input_ids.cuda()\n",
    "output = model.generate(inputs=input_ids, temperature=0.7, do_sample=True, top_p=0.95, top_k=40, max_new_tokens=512)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10095cc9-b00d-4641-bbc7-34fc89ae8383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
